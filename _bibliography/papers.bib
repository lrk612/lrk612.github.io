---
---

@article{li2026pixel2phys,
  title={Pixel2Phys: Distilling Governing Laws from Visual Dynamics},
  author={Li, Ruikun and Lu, Yan and Tang, Shixiang and Qi, Biqing and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2505.11940},
  year={2026},
  abbr={CVPR},
  selected={true},
  arxiv={2505.11940},
  abstract={Discovering physical laws directly from high-dimensional visual data is a long-standing human pursuit but remains a formidable challenge for machines, representing a fundamental goal of scientific intelligence. This task is inherently difficult because physical knowledge is low-dimensional and structured, whereas raw video observations are high-dimensional and redundant, with most pixels carrying little or no physical meaning. Extracting concise, physically relevant variables from such noisy data remains a key obstacle. To address this, we propose Pixel2Phys, a collaborative multi-agent framework adaptable to any Multimodal Large Language Model (MLLM). It emulates human scientific reasoning by employing a structured workflow to extract formalized physical knowledge through iterative hypothesis generation, validation, and refinement.By repeatedly formulating, and refining candidate equations on high-dimensional data, it identifies the most concise representations that best capture the underlying physical evolution. This automated exploration mimics the iterative workflow of human scientists, enabling AI to reveal interpretable governing equations directly from raw observations. Across diverse simulated and real-world physics videos, Pixel2Phys discovers accurate, interpretable governing equations and maintaining stable long-term extrapolation where baselines rapidly diverge.},
  bibtex_show={true},
}

@article{zhou2025zero,
  title={Zero-Shot Forecasting of Network Dynamics through Weight Flow Matching},
  author={Zhou, Shihe and Li, Ruikun and Wang, Huandong and Li, Yong},
  journal={arXiv preprint arXiv:2510.07957},
  year={2025},
  abbr={Preprint},
  selected={false},
  arxiv={2510.07957},
  abstract={Forecasting state evolution of network systems, such as the spread of information on social networks, is significant for effective policy interventions and resource management. However, the underlying propagation dynamics constantly shift with new topics or events, which are modeled as changing coefficients of the underlying dynamics. Deep learning models struggle to adapt to these out-of-distribution shifts without extensive new data and retraining. To address this, we present Zero-Shot Forecasting of Network Dynamics through Weight Flow Matching (FNFM), a generative, coefficient-conditioned framework that generates dynamic model weights for an unseen target coefficient, enabling zero-shot forecasting. Our framework utilizes a Variational Encoder to summarize the forecaster weights trained in observed environments into compact latent tokens. A Conditional Flow Matching (CFM) module then learns a continuous transport from a simple Gaussian distribution to the empirical distribution of these weights, conditioned on the dynamical coefficients. This process is instantaneous at test time and requires no gradient-based optimization. Across varied dynamical coefficients, empirical results indicate that FNFM yields more reliable zero-shot accuracy than baseline methods, particularly under pronounced coefficient shift.},
  bibtex_show={true},
}


@article{li2025weightflow,
  title={WeightFlow: Learning Stochastic Dynamics via Evolving Weight of Neural Network},
  author={Li, Ruikun and Liu, Jiazhen and Wang, Huandong and Liao, Qingmin and Li, Yong},
  journal={AAAI},
  year={2025},
  abbr={AAAI},
  selected={true},
  arxiv={2508.00451},
  abstract={Modeling stochastic dynamics from discrete observations is a key interdisciplinary challenge. Existing methods often fail to estimate the continuous evolution of probability densities from trajectories or face the curse of dimensionality. To address these limitations, we presents a novel paradigm: modeling dynamics directly in the weight space of a neural network by projecting the evolving probability distribution. We first theoretically establish the connection between dynamic optimal transport in measure space and an equivalent energy functional in weight space. Subsequently, we design WeightFlow, which constructs the neural network weights into a graph and learns its evolution via a graph controlled differential equation. Experiments on interdisciplinary datasets demonstrate that WeightFlow improves performance by an average of 43.02\% over state-of-the-art methods, providing an effective and scalable solution for modeling high-dimensional stochastic dynamics.},
  bibtex_show={true},
  code={https://github.com/tsinghua-fib-lab/WeightFlow},
}


@article{hua2025finetuning,
  title={Finetuning Large Language Model as an Effective Symbolic Regressor},
  author={Hua, Yingfan and Li, Ruikun and Yao, Jun and Zhuang, Guohang and Tang, Shixiang and Liu, Bin and Ouyang, Wanli and Lu, Yan},
  journal={arXiv preprint arXiv:2508.09897},
  year={2025},
  abbr={Preprint},
  selected={false},
  arxiv={2508.09897},
  abstract={Deriving governing equations from observational data, known as Symbolic Regression (SR), is a cornerstone of scientific discovery. Large Language Models, (LLMs) have shown promise in this task by leveraging their vast cross-disciplinary scientific knowledge. However, existing LLM-based methods primarily rely on direct inference or prompt engineering, often requiring excessive inference iterations to converge on correct formulas or failing to treat complex equation targets. These limitations in effectiveness and generalization stem from an inherent tension between pre-trained LLMs' proficiency in approximate reasoning and the high-precision demands of SR tasks. To bridge this gap, we propose to fine-tune LLMs for enhanced SR capability. Yet, the absence of dedicated datasets for SR-oriented fine-tuning remains a critical barrier. We thus introduce SymbArena, specifically engineered to optimize LLMs for SR. This benchmark comprises over 148,000 diverse equations formulated as corpora of 1.83 billion tokens for LLM utilization, enabling effective training and inference. Further, to ensure a more comprehensive and fair evaluation, SymbArena proposes a heuristics metric to precisely quantify form-level consistency, going beyond existing SR numerical-oriented evaluation strategies. With this benchmark, we explore mainstream LLM fine-tuning techniques for SR tasks and establish Symbolic-R1, a simple yet effective LLM-based SR strong baseline. Experimental results validate Symbolic-R1 as the first LLM to exceed traditional numerical methods in both numerical precision and symbolic form accuracy, outperforming the second-best LLM baseline with improvements of 2-fold gains in R2 score and 10.3% in form-level consistency score.},
  bibtex_show={true},
}


@article{li2025predicting3,
  title={Predicting Dynamical Systems across Environments via Diffusive Model Weight Generation},
  author={Li, Ruikun and Wang, Huandong and Ding, Jingtao and Yuan, Yuan and Liao, Qingmin and Li, Yong},
  journal={arXiv preprint arXiv:2505.13919},
  year={2025},
  abbr={Preprint},
  selected={true},
  arxiv={2505.13919},
  abstract={Data-driven methods offer an effective equation-free solution for predicting physical dynamics. However, the same physical system can exhibit significantly different dynamic behaviors in various environments. This causes prediction functions trained for specific environments to fail when transferred to unseen environments. Therefore, cross-environment prediction requires modeling the dynamic functions of different environments. In this work, we propose a model weight generation method, EnvAd-Diff. EnvAd-Diff operates in the weight space of the dynamic function, generating suitable weights from scratch based on environmental condition for zero-shot prediction. Specifically, we first train expert prediction functions on dynamic trajectories from a limited set of visible environments to create a model zoo, thereby constructing sample pairs of prediction function weights and their corresponding environments. Subsequently, we train a latent space diffusion model conditioned on the environment to model the joint distribution of weights and environments. Considering the lack of environmental prior knowledge in real-world scenarios, we propose a physics-informed surrogate label to distinguish different environments. Generalization experiments across multiple systems demonstrate that a 1M parameter prediction function generated by EnvAd-Diff outperforms a pre-trained 500M parameter foundation model.},
  bibtex_show={true},
}


@article{li2025predicting,
  title={Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning},
  author={Li, Ruikun and Wang, Huandong and Liao, Qingmin and Li, Yong},
  journal={ICLR},
  year={2025},
  abbr={ICLR},
  selected={true},
  abstract={Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65\%.},
  bibtex_show={true},
  code={https://github.com/tsinghua-fib-lab/PESLA},
}

@article{li2025predicting2,
  title={Predicting the Dynamics of Complex System via Multiscale Diffusion Autoencoder},
  author={Li, Ruikun and Cheng, Jingwen and Wang, Huandong and Liao, Qingmin and Li, Yong},
  journal={KDD},
  year={2025},
  abbr={KDD},
  selected={true},
  abstract={Predicting the dynamics of complex systems is crucial for various scientific and engineering applications. The accuracy of predictions depends on the model's ability to capture the intrinsic dynamics. While existing methods capture key dynamics by encoding a low-dimensional latent space, they overlook the inherent multiscale structure of complex systems, making it difficult to accurately predict complex spatiotemporal evolution. Therefore, we propose a Multiscale Diffusion Prediction Network (MDPNet) that leverages the multiscale structure of complex systems to discover the latent space of intrinsic dynamics. First, we encode multiscale features through a multiscale diffusion autoencoder to guide the diffusion model for reliable reconstruction. Then, we introduce an attention-based graph neural ordinary differential equation to model the co-evolution across different scales. Extensive evaluations on representative systems demonstrate that the proposed method achieves an average prediction error reduction of 53.23% compared to baselines, while also exhibiting superior robustness and generalization.},
  bibtex_show={true},
  code={https://github.com/tsinghua-fib-lab/MDPNet},
}

@article{li2024predicting,
  title={Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space},
  author={Li, Ruikun and Wang, Huandong and Piao, Jinghua and Liao, Qingmin and Li, Yong},
  journal={KDD},
  year={2024},
  abbr={KDD},
  selected={true},
  abstract={Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the <u>D</u>ynamics-<u>I</u>nvariant <u>Sk</u>eleton Neural <u>Net</u>work (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18% in terms of long-term prediction accuracy.},
  bibtex_show={true},
  code={https://github.com/tsinghua-fib-lab/DiskNet},
}

@article{li2023learning,
  title={Learning slow and fast system dynamics via automatic separation of time scales},
  author={Li, Ruikun and Wang, Huandong and Li, Yong},
  journal={KDD},
  year={2023},
  abbr={KDD},
  selected={true},
  abstract={Learning the underlying slow and fast dynamics of a system is instrumental for many practical applications related to the system. However, existing approaches are limited in discovering the appropriate time scale to separate the slow and fast variables and effectively learning their dynamics based on correct-dimensional representation vectors. In this paper, we introduce a framework that effectively learns slow and fast system dynamics in an integrated manner. We propose a novel intrinsic dimensionality (ID) driven learning method based on a time-lagged autoencoder framework to identify appropriate time scales to separate slow and fast variables and their IDs simultaneously. Further, we propose an integrated framework to concurrently learn the system's slow and fast dynamics, which is able to integrate prior knowledge of time scale and IDs and model the complex coupled slow and fast variables. Extensive experimental results on two representative dynamical systems show that our proposed framework is able to efficiently learn slow and fast system dynamics. Specifically, the long-time prediction performance is able to be improved by 36% on average compared with four representative baselines based on our proposed framework. Furthermore, our proposed system is able to extract interpretable slow and fast dynamics highly correlated with the known slow and fast variables in the dynamical systems.},
  bibtex_show={true},
  code={https://github.com/tsinghua-fib-lab/SlowFastSeparation},
}

@article{liu2025beyond,
  title={Beyond Equilibrium: Non-Equilibrium Foundations Should Underpin Generative Processes in Complex Dynamical Systems},
  author={Liu†, Jiazhen and Li†, Ruikun and Wang, Huandong and Yu, Zihan and Liu, Chang and Ding, Jingtao and Li, Yong},
  journal={arXiv preprint arXiv:2505.18621},
  year={2025},
  abbr={Preprint},
  selected={false},
  arxiv={2505.18621},
  abstract={This position paper argues that next-generation non-equilibrium-inspired generative models will provide the essential foundation for better modeling real-world complex dynamical systems. While many classical generative algorithms draw inspiration from equilibrium physics, they are fundamentally limited in representing systems with transient, irreversible, or far-from-equilibrium behavior. We show that non-equilibrium frameworks naturally capture non-equilibrium processes and evolving distributions. Through empirical experiments on a dynamic Printz potential system, we demonstrate that non-equilibrium generative models better track temporal evolution and adapt to non-stationary landscapes. We further highlight future directions such as integrating non-equilibrium principles with generative AI to simulate rare events, inferring underlying mechanisms, and representing multi-scale dynamics across scientific domains. Our position is that embracing non-equilibrium physics is not merely beneficial--but necessary--for generative AI to serve as a scientific modeling tool, offering new capabilities for simulating, understanding, and controlling complex systems.},
  bibtex_show={true},
}

@article{cheng2025sparse,
  title={Sparse Diffusion Autoencoder for Test-time Adapting Prediction of Complex Systems},
  author={Cheng†, Jingwen and Li†, Ruikun and Wang, Huandong and Li, Yong},
  journal={NeurIPS},
  year={2025},
  abbr={NeurIPS},
  selected={false},
  arxiv={2505.17459},
  abstract={Predicting the behavior of complex systems is critical in many scientific and engineering domains, and hinges on the model's ability to capture their underlying dynamics. Existing methods encode the intrinsic dynamics of high-dimensional observations through latent representations and predict autoregressively. However, these latent representations lose the inherent spatial structure of spatiotemporal dynamics, leading to the predictor's inability to effectively model spatial interactions and neglect emerging dynamics during long-term prediction. In this work, we propose SparseDiff, introducing a test-time adaptation strategy to dynamically update the encoding scheme to accommodate emergent spatiotemporal structures during the long-term evolution of the system. Specifically, we first design a codebook-based sparse encoder, which coarsens the continuous spatial domain into a sparse graph topology. Then, we employ a graph neural ordinary differential equation to model the dynamics and guide a diffusion decoder for reconstruction. SparseDiff autoregressively predicts the spatiotemporal evolution and adjust the sparse topological structure to adapt to emergent spatiotemporal patterns by adaptive re-encoding. Extensive evaluations on representative systems demonstrate that SparseDiff achieves an average prediction error reduction of 49.99\% compared to baselines, requiring only 1\% of the spatial resolution.},
  bibtex_show={true},
}

@article{ding2024artificial,
  title={Artificial intelligence for complex network: Potential, methodology and application},
  author={Ding, Jingtao and Liu, Chang and Zheng, Yu and Zhang, Yunke and Yu, Zihan and Li, Ruikun and Chen, Hongyi and Piao, Jinghua and Wang, Huandong and Liu, Jiazhen and others},
  journal={arXiv preprint arXiv:2402.16887},
  year={2024},
  abbr={Preprint},
  selected={false},
  arxiv={2402.16887},
  abstract={This tutorial will explore the fascinating domain of empirical network modeling through artificial intelligence (AI) techniques, with applications across social media, web systems, and urban environments. Participants will gain valuable insights into incorporating advanced AI methods-such as graph machine learning, deep reinforcement learning, and generative models-within complex network science. The goal is to provide a comprehensive understanding of how these models can effectively represent, predict, and control empirical networked systems with heterogeneous structures and dynamic processes. The tutorial will begin by introducing essential background knowledge, outlining motivations and challenges, exploring recent methodological advances, and highlighting key applications.},
  bibtex_show={true},
}